{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import newspaper\n",
    "from newspaper import Article\n",
    "import pyPdf\n",
    "import urllib2\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"un_traing.pkl\", 'rb') as picklefile:\n",
    "   urls = pickle.load(picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "688"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_file(url):\n",
    "    try:\n",
    "        response = urllib2.urlopen(url)\n",
    "        file = open(\"document.pdf\", 'wb')\n",
    "        file.write(response.read())\n",
    "        file.close()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def html_pages(url):\n",
    "    info = {}\n",
    "    try:\n",
    "        article = Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        article.nlp()\n",
    "\n",
    "        valid = article.is_valid_url()\n",
    "        authors = article.authors\n",
    "        date = article.publish_date\n",
    "        text = article.text\n",
    "        keywords = article.keywords\n",
    "        summary = article.summary\n",
    "        image = article.top_image\n",
    "\n",
    "        info['url'] = url\n",
    "        info['valid'] = valid\n",
    "        info['authors'] = authors\n",
    "        info['date'] = date\n",
    "        info['text'] = text\n",
    "        info['keywords'] = keywords\n",
    "        info['summary'] = summary\n",
    "        info['image'] = image\n",
    "\n",
    "        all_text.append(info)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getPDFContent(url):\n",
    "    pdf_info = {}\n",
    "    content = \"\"\n",
    "    pdf = pyPdf.PdfFileReader(file(\"document.pdf\", \"rb\"))\n",
    "    for i in range(0, pdf.getNumPages()):\n",
    "        content += pdf.getPage(i).extractText() + \"\\n\"\n",
    "        content = content.encode('ascii', 'ignore')\n",
    "    pdf_info['url'] = url\n",
    "    pdf_info['text'] = content\n",
    "    all_text.append(pdf_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    download_file(url)\n",
    "    try:\n",
    "        getPDFContent(url)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        html_pages(url)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>image</th>\n",
       "      <th>keywords</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United Nations  S/2015/302   Security Council...</td>\n",
       "      <td>http://www.securitycouncilreport.org/atf/cf/%7...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://www.securitycouncilreport.org/atf/cf/%7...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Heather Saul]</td>\n",
       "      <td>2013-08-05 12:33:51+01:00</td>\n",
       "      <td>https://static.independent.co.uk/s3fs-public/t...</td>\n",
       "      <td>[pakistan, homes, remote, afghanistan, floodin...</td>\n",
       "      <td>Flash flooding across Afghanistan and Pakistan...</td>\n",
       "      <td>Flash flooding across Afghanistan and Pakistan...</td>\n",
       "      <td>http://www.independent.co.uk/news/world/asia/1...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>www.unocha.org The mission of the United Natio...</td>\n",
       "      <td>http://reliefweb.int/sites/reliefweb.int/files...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>http://reliefweb.int/sites/reliefweb.int/files...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          authors                       date  \\\n",
       "0             NaN                        NaN   \n",
       "1              []                       None   \n",
       "2  [Heather Saul]  2013-08-05 12:33:51+01:00   \n",
       "3             NaN                        NaN   \n",
       "4              []                       None   \n",
       "\n",
       "                                               image  \\\n",
       "0                                                NaN   \n",
       "1                                                      \n",
       "2  https://static.independent.co.uk/s3fs-public/t...   \n",
       "3                                                NaN   \n",
       "4                                                      \n",
       "\n",
       "                                            keywords  \\\n",
       "0                                                NaN   \n",
       "1                                                 []   \n",
       "2  [pakistan, homes, remote, afghanistan, floodin...   \n",
       "3                                                NaN   \n",
       "4                                                 []   \n",
       "\n",
       "                                             summary  \\\n",
       "0                                                NaN   \n",
       "1                                                      \n",
       "2  Flash flooding across Afghanistan and Pakistan...   \n",
       "3                                                NaN   \n",
       "4                                                      \n",
       "\n",
       "                                                text  \\\n",
       "0   United Nations  S/2015/302   Security Council...   \n",
       "1                                                      \n",
       "2  Flash flooding across Afghanistan and Pakistan...   \n",
       "3  www.unocha.org The mission of the United Natio...   \n",
       "4                                                      \n",
       "\n",
       "                                                 url  valid  \n",
       "0  http://www.securitycouncilreport.org/atf/cf/%7...    NaN  \n",
       "1  http://www.securitycouncilreport.org/atf/cf/%7...  False  \n",
       "2  http://www.independent.co.uk/news/world/asia/1...   True  \n",
       "3  http://reliefweb.int/sites/reliefweb.int/files...    NaN  \n",
       "4  http://reliefweb.int/sites/reliefweb.int/files...  False  "
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(880, 8)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"df_training.pkl\", 'wb') as picklefile:\n",
    "    pickle.dump(df, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
